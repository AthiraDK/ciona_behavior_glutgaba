{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import openpyxl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.signal import savgol_filter\n",
    "import re\n",
    "import difflib\n",
    "import pickle\n",
    "import h5py\n",
    "import itertools\n",
    "import cv2\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../project_behaviour/Code/\")\n",
    "\n",
    "from extract_angles import get_bend_angles, get_tan_angles, savgol_skeleton\n",
    "from extract_curvatures import get_curv_savgol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata_drugs = pd.read_pickle('/data/temp/athira/dlc_analysis/ref_metadataframe_drugs_Jan26.pickle')\n",
    "df_metadata_drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>filename</th>\n",
       "      <th>drug</th>\n",
       "      <th>folder</th>\n",
       "      <th>drug_std</th>\n",
       "      <th>is_dechorionated</th>\n",
       "      <th>is_control</th>\n",
       "      <th>dissolved_in</th>\n",
       "      <th>with_CNO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/data/temp/athira/dlc_analysis/dlc_analysis_me...</td>\n",
       "      <td>20211112_085810_1_15m0s_CNO_VGLUThm4D_None_INV...</td>\n",
       "      <td>VGLUTKH.C3.324hm4DcherryCNO</td>\n",
       "      <td>dlc_analysis_meike_drugsWT_v4</td>\n",
       "      <td>VGLUTKH.C3.324hm4DcherryCNO</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/data/temp/athira/dlc_analysis/dlc_analysis_me...</td>\n",
       "      <td>20211112_152313_1_15m0s_CNO_VGLUThm4D_None_INV...</td>\n",
       "      <td>VGLUTKH.C3.324hm4DcherryCNO</td>\n",
       "      <td>dlc_analysis_meike_drugsWT_v4</td>\n",
       "      <td>VGLUTKH.C3.324hm4DcherryCNO</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/data/temp/athira/dlc_analysis/dlc_analysis_me...</td>\n",
       "      <td>20211112_131733_1_15m0s_CNO_VGLUThm4D_None_INV...</td>\n",
       "      <td>VGLUTKH.C3.324hm4DcherryCNO</td>\n",
       "      <td>dlc_analysis_meike_drugsWT_v4</td>\n",
       "      <td>VGLUTKH.C3.324hm4DcherryCNO</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/data/temp/athira/dlc_analysis/dlc_analysis_me...</td>\n",
       "      <td>20211112_121207_1_15m0s_CNO_VGLUThm4D_None_INV...</td>\n",
       "      <td>VGLUTKH.C3.324hm4DcherryCNO</td>\n",
       "      <td>dlc_analysis_meike_drugsWT_v4</td>\n",
       "      <td>VGLUTKH.C3.324hm4DcherryCNO</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/data/temp/athira/dlc_analysis/dlc_analysis_me...</td>\n",
       "      <td>20211112_152311_1_15m0s_CNO_VGLUThm4D_None_INV...</td>\n",
       "      <td>VGLUTKH.C3.324hm4DcherryCNO</td>\n",
       "      <td>dlc_analysis_meike_drugsWT_v4</td>\n",
       "      <td>VGLUTKH.C3.324hm4DcherryCNO</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4919</th>\n",
       "      <td>/data/temp/athira/dlc_analysis/dlc_analysis_me...</td>\n",
       "      <td>20211005_162645_1_15m0s_CNO_THhM3D_None_INVERT...</td>\n",
       "      <td>THhM3DmcherryCNO</td>\n",
       "      <td>dlc_analysis_meike_drugsWT_v2</td>\n",
       "      <td>THhM3DmcherryCNO</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>/data/temp/athira/dlc_analysis/dlc_analysis_me...</td>\n",
       "      <td>20211005_140538_1_15m0s_CNO_THhM3D_None_INVERT...</td>\n",
       "      <td>THhM3DmcherryCNO</td>\n",
       "      <td>dlc_analysis_meike_drugsWT_v2</td>\n",
       "      <td>THhM3DmcherryCNO</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4921</th>\n",
       "      <td>/data/temp/athira/dlc_analysis/dlc_analysis_me...</td>\n",
       "      <td>20211005_135035_1_15m0s_CNO_THhM3D_None_INVERT...</td>\n",
       "      <td>THhM3DmcherryCNO</td>\n",
       "      <td>dlc_analysis_meike_drugsWT_v2</td>\n",
       "      <td>THhM3DmcherryCNO</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4922</th>\n",
       "      <td>/data/temp/athira/dlc_analysis/dlc_analysis_me...</td>\n",
       "      <td>20211005_143719_1_15m0s_CNO_THhM3D_None_INVERT...</td>\n",
       "      <td>THhM3DmcherryCNO</td>\n",
       "      <td>dlc_analysis_meike_drugsWT_v2</td>\n",
       "      <td>THhM3DmcherryCNO</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4923</th>\n",
       "      <td>/data/temp/athira/dlc_analysis/dlc_analysis_me...</td>\n",
       "      <td>20211005_135037_1_15m0s_CNO_THhM3D_None_INVERT...</td>\n",
       "      <td>THhM3DmcherryCNO</td>\n",
       "      <td>dlc_analysis_meike_drugsWT_v2</td>\n",
       "      <td>THhM3DmcherryCNO</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1954 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               filepath  \\\n",
       "8     /data/temp/athira/dlc_analysis/dlc_analysis_me...   \n",
       "9     /data/temp/athira/dlc_analysis/dlc_analysis_me...   \n",
       "10    /data/temp/athira/dlc_analysis/dlc_analysis_me...   \n",
       "11    /data/temp/athira/dlc_analysis/dlc_analysis_me...   \n",
       "12    /data/temp/athira/dlc_analysis/dlc_analysis_me...   \n",
       "...                                                 ...   \n",
       "4919  /data/temp/athira/dlc_analysis/dlc_analysis_me...   \n",
       "4920  /data/temp/athira/dlc_analysis/dlc_analysis_me...   \n",
       "4921  /data/temp/athira/dlc_analysis/dlc_analysis_me...   \n",
       "4922  /data/temp/athira/dlc_analysis/dlc_analysis_me...   \n",
       "4923  /data/temp/athira/dlc_analysis/dlc_analysis_me...   \n",
       "\n",
       "                                               filename  \\\n",
       "8     20211112_085810_1_15m0s_CNO_VGLUThm4D_None_INV...   \n",
       "9     20211112_152313_1_15m0s_CNO_VGLUThm4D_None_INV...   \n",
       "10    20211112_131733_1_15m0s_CNO_VGLUThm4D_None_INV...   \n",
       "11    20211112_121207_1_15m0s_CNO_VGLUThm4D_None_INV...   \n",
       "12    20211112_152311_1_15m0s_CNO_VGLUThm4D_None_INV...   \n",
       "...                                                 ...   \n",
       "4919  20211005_162645_1_15m0s_CNO_THhM3D_None_INVERT...   \n",
       "4920  20211005_140538_1_15m0s_CNO_THhM3D_None_INVERT...   \n",
       "4921  20211005_135035_1_15m0s_CNO_THhM3D_None_INVERT...   \n",
       "4922  20211005_143719_1_15m0s_CNO_THhM3D_None_INVERT...   \n",
       "4923  20211005_135037_1_15m0s_CNO_THhM3D_None_INVERT...   \n",
       "\n",
       "                             drug                         folder  \\\n",
       "8     VGLUTKH.C3.324hm4DcherryCNO  dlc_analysis_meike_drugsWT_v4   \n",
       "9     VGLUTKH.C3.324hm4DcherryCNO  dlc_analysis_meike_drugsWT_v4   \n",
       "10    VGLUTKH.C3.324hm4DcherryCNO  dlc_analysis_meike_drugsWT_v4   \n",
       "11    VGLUTKH.C3.324hm4DcherryCNO  dlc_analysis_meike_drugsWT_v4   \n",
       "12    VGLUTKH.C3.324hm4DcherryCNO  dlc_analysis_meike_drugsWT_v4   \n",
       "...                           ...                            ...   \n",
       "4919             THhM3DmcherryCNO  dlc_analysis_meike_drugsWT_v2   \n",
       "4920             THhM3DmcherryCNO  dlc_analysis_meike_drugsWT_v2   \n",
       "4921             THhM3DmcherryCNO  dlc_analysis_meike_drugsWT_v2   \n",
       "4922             THhM3DmcherryCNO  dlc_analysis_meike_drugsWT_v2   \n",
       "4923             THhM3DmcherryCNO  dlc_analysis_meike_drugsWT_v2   \n",
       "\n",
       "                         drug_std is_dechorionated is_control dissolved_in  \\\n",
       "8     VGLUTKH.C3.324hm4DcherryCNO             True        NaN          NaN   \n",
       "9     VGLUTKH.C3.324hm4DcherryCNO             True        NaN          NaN   \n",
       "10    VGLUTKH.C3.324hm4DcherryCNO             True        NaN          NaN   \n",
       "11    VGLUTKH.C3.324hm4DcherryCNO             True        NaN          NaN   \n",
       "12    VGLUTKH.C3.324hm4DcherryCNO             True        NaN          NaN   \n",
       "...                           ...              ...        ...          ...   \n",
       "4919             THhM3DmcherryCNO             True        NaN          NaN   \n",
       "4920             THhM3DmcherryCNO             True        NaN          NaN   \n",
       "4921             THhM3DmcherryCNO             True        NaN          NaN   \n",
       "4922             THhM3DmcherryCNO             True        NaN          NaN   \n",
       "4923             THhM3DmcherryCNO             True        NaN          NaN   \n",
       "\n",
       "     with_CNO  \n",
       "8        True  \n",
       "9        True  \n",
       "10       True  \n",
       "11       True  \n",
       "12       True  \n",
       "...       ...  \n",
       "4919     True  \n",
       "4920     True  \n",
       "4921     True  \n",
       "4922     True  \n",
       "4923     True  \n",
       "\n",
       "[1954 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metadata_dreadds = pd.read_pickle('/data/temp/athira/dlc_analysis/ref_metadataframe_dreadds_Feb06.pickle')\n",
    "df_metadata_dreadds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['VGLUTKH.C3.324hm4DcherryCNO', 'KH.C2.526VGAThm4Dcherry',\n",
       "       'KH.C2.526VGAThm3Dcherry', 'VGLUTKH.C3.324hm4Dcherry',\n",
       "       'KH.C2.526VGAThm4DcherryCNO', 'KH.C2.526VGAThm3DcherryCNO',\n",
       "       'DDChM4Dmcherry', 'THhM3Dmcherry', 'VGLUTKH.C3.324hm3Dcherry',\n",
       "       'THhM4Dmcherry', 'THhM3DmcherryCNO', 'VGLUTKH.C3.324hm3DcherryCNO',\n",
       "       'THhM4DmcherryCNO', 'DDChM3Dmcherry', 'DDChM3DmcherryCNO',\n",
       "       'DDChM4DmcherryCNO'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metadata_dreadds.drug_std.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata_drugs.drug_std.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_dict_july13 = np.load('../paleontology/eigen_dict_July13.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_boundaries_lower(neck):\n",
    "    \n",
    "    tail_length = 48-(neck+2)+1\n",
    "    tail_seg_len = int(np.round(tail_length / 5))\n",
    "    \n",
    "    segments_ind = {     \n",
    "                'head' : 0,\n",
    "                'neck' : (neck-1), \n",
    "                'tail_base': (neck+2),\n",
    "                'tail_pre_mid': (neck+2)+ tail_seg_len,\n",
    "                'tail_mid': (neck+2)+ 2*tail_seg_len,\n",
    "                'tail_post_mid': (neck+2)+ 3*tail_seg_len,\n",
    "                'tail_tip': (neck+2)+ 4*tail_seg_len\n",
    "            }\n",
    "    \n",
    "#     max_skel_index = 48 # contour_width.shape[-1] - 1 # default : 48\n",
    "#     segments_ind = { k: int(round(x*max_skel_index)) for k,x in segments_ind.items()}\n",
    "    \n",
    "    #Note : Here the indices are in 0 to 48 range\n",
    "    return segments_ind\n",
    "\n",
    "\n",
    "\n",
    "def segment_boundaries_upper(neck):\n",
    "    \n",
    "    tail_length = 48-(neck+2)+1\n",
    "    tail_seg_len = int(np.round(tail_length / 5))\n",
    "    \n",
    "    segments_ind = {       \n",
    "                'head' : (neck-2),\n",
    "                'neck' : (neck+1), \n",
    "                'tail_base': ((neck+2)+ tail_seg_len)-1,\n",
    "                'tail_pre_mid': ((neck+2)+ 2*tail_seg_len)-1,\n",
    "                'tail_mid': ((neck+2)+ 3*tail_seg_len)-1,\n",
    "                'tail_post_mid': ((neck+2)+ 4*tail_seg_len)-1,\n",
    "                'tail_tip': 48\n",
    "            }\n",
    "    \n",
    "#     max_skel_index = 48 \n",
    "#     segments_ind = { k: int(round(x*max_skel_index)) for k,x in segments_ind.items()}\n",
    "    \n",
    "    #Note : Here the indices are in 0 to 48 range\n",
    "    return segments_ind   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_centroids_fw(neck_point):\n",
    "    \n",
    "    seg_ind_lower = segment_boundaries_lower(neck_point)\n",
    "    seg_ind_upper = segment_boundaries_upper(neck_point)\n",
    "    \n",
    "    centroid_dict = {}\n",
    "    \n",
    "    for key in seg_ind_lower.keys():\n",
    "        \n",
    "        centroid_dict[key] = ((seg_ind_lower[key] + seg_ind_upper[key])//2)\n",
    "    \n",
    "    centroid_dict['neck'] = neck_point\n",
    "\n",
    "    return centroid_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features_dataframe(file_path, drug):\n",
    "    \n",
    "    try:\n",
    "        df_skeleton = pd.read_hdf(file_path)\n",
    "        print(len(df_skeleton.index),df_skeleton.isna().sum().sum())\n",
    "        \n",
    "        df_skeleton[df_skeleton < 0] = np.nan\n",
    "        df_skeleton = df_skeleton[(df_skeleton.iloc[:, df_skeleton.columns.get_level_values(2) == 'likelihood'] > 0.6).all(axis=1)]\n",
    "        df_skeleton = df_skeleton.dropna()\n",
    "#         print((df_skeleton.max()),(df_skeleton.min()))\n",
    "        print(len(df_skeleton.index),df_skeleton.isna().sum().sum())\n",
    "    \n",
    "        if len(df_skeleton.index) > 200:\n",
    "    \n",
    "            skel_array = df_skeleton.iloc[:,df_skeleton.columns.get_level_values(2)!='likelihood'].values.reshape(-1,49,2)\n",
    "\n",
    "            curv_array = get_curv_savgol(skel_array)\n",
    "\n",
    "            frame_indices = list(df_skeleton.index)\n",
    "#             print(frame_indices)\n",
    "            true_frame_indices = frame_indices#list(itertools.compress(range(len(frame_indices)), frame_indices)) \n",
    "            print(true_frame_indices[0:5])\n",
    "\n",
    "            speed_array = np.diff(skel_array,prepend=skel_array[1,:,:].reshape(1,-1,2), axis = 0)\n",
    "            delta_time = (np.diff(true_frame_indices, prepend=true_frame_indices[0]-1))\n",
    "            print(delta_time)\n",
    "            print(np.unique(delta_time))\n",
    "            speed_array = np.divide(speed_array,delta_time[:,None,None])\n",
    "\n",
    "\n",
    "            neck_pt = 12\n",
    "            #lower bounds of segments\n",
    "            lb_list = [segment_boundaries_lower(neck_pt)] * len(skel_array)\n",
    "            #upper bounds of segments\n",
    "            ub_list = [segment_boundaries_upper(neck_pt)] * len(skel_array)\n",
    "            #centroids of segments\n",
    "            centroid_list = [calc_centroids_fw(neck_pt)] * len(skel_array)\n",
    "\n",
    "            # create a dataframe for an indexing operation down the line\n",
    "            df_indices_lb = pd.DataFrame(lb_list)\n",
    "            df_indices_ub = pd.DataFrame(ub_list)\n",
    "            df_indices = pd.DataFrame(centroid_list)\n",
    "\n",
    "            # List of segment names\n",
    "            cols = list(centroid_list[0].keys())\n",
    "\n",
    "            df_skel_file = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "            # segment wise : centroids\n",
    "            for key in cols:\n",
    "\n",
    "                # get the indices of the cenroid of the segment for all frames\n",
    "                y = df_indices[key].values\n",
    "                # get the indices of the lower boundary of the segment for all frames\n",
    "                y_lb = df_indices_lb[key].values\n",
    "                # get the indices of the upper boundary of the segment for all frames\n",
    "                y_ub = df_indices_ub[key].values\n",
    "\n",
    "                # get the valid frame indices (Elaborate: slack comment)\n",
    "                ind_y = np.indices(y.shape)[0]\n",
    "            #         print(skel_array.shape, curv_array.shape, skel_array.shape, curv_array.shape, \n",
    "            #               len(ind_y), len(y_lb), len(y_ub))  \n",
    "\n",
    "                # Feature 1 : Curvature to the dataframe------------------\n",
    "                df_skel_file[f\"curv_{key}\"] = curv_array[ind_y, y]\n",
    "\n",
    "                # Feature 2 : speed and velocities------------------------\n",
    "        #         df_skel_file[f\"speed_x_{key}\"] = speed_array[ind_y, y, 0]\n",
    "        #         df_skel_file[f\"speed_y_{key}\"] = speed_array[ind_y, y, 1]\n",
    "                df_skel_file[f\"speed_{key}\"] = np.linalg.norm(speed_array[ind_y, y, :], axis = 1)\n",
    "                print(df_skel_file[f\"speed_{key}\"].max())\n",
    "\n",
    "                # Feature 3 : Tangent angles--------------------------------\n",
    "                # Calculate tan angles\n",
    "                x_diff = skel_array[ind_y,y_ub,0]-skel_array[ind_y,y_lb,0]\n",
    "                y_diff = skel_array[ind_y,y_ub,1]-skel_array[ind_y,y_lb,1]\n",
    "                tan_array = np.arctan2(y_diff,x_diff)\n",
    "                # To be done or not (attempt to make it unilateral - same side of the skeleton..)\n",
    "                tan_array[tan_array < 0] += 2*np.pi\n",
    "                df_skel_file[f\"tan_{key}\"] = tan_array\n",
    "\n",
    "            # Feature 5 : Relative tangent angles using segments' tan angles\n",
    "            for key in cols:\n",
    "                if key != 'head':\n",
    "                    df_skel_file[f\"rel_tan_{key}\"] = df_skel_file[f\"tan_{key}\"] - df_skel_file[\"tan_head\"]\n",
    "\n",
    "            # Feature 6 : EIGEN FEATURES\n",
    "            curv_array_for_eig = curv_array[:,: -1]\n",
    "            # Compute eigen coefficients\n",
    "            eig_vec_matrix = np.array(eig_dict_july13['eig_vecs'][:,0:eig_dict_july13['n_modes']])   \n",
    "            ects_test = np.dot(curv_array_for_eig, eig_vec_matrix)\n",
    "\n",
    "            for i in range(ects_test.shape[1]):\n",
    "                df_skel_file[f\"ects_{i+1}\"] = ects_test[:,i]\n",
    "\n",
    "\n",
    "            # Feature 7 : calculate quirkiness\n",
    "            dd = [cv2.minAreaRect(x) for x in skel_array.astype(np.float32)]\n",
    "            dd = [(L,W) if L >W else (W,L) for _,(L,W),_ in dd]\n",
    "            L, W = list(map(np.array, zip(*dd)))\n",
    "            quirkiness = np.sqrt(1 - W**2 / L**2)\n",
    "            df_skel_file['quirkness'] = quirkiness\n",
    "\n",
    "            df_skel_file['frames'] = frame_indices#np.arange(len(skel_array))\n",
    "            df_skel_file['filename'] = os.path.basename(file_path)\n",
    "            df_skel_file['filedir'] = Path(file_path).parent.as_posix()\n",
    "            df_skel_file['drug'] = drug\n",
    "            return df_skel_file\n",
    "        \n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f'FileNotFoundError : {file_path}')\n",
    "        return None\n",
    "\n",
    "    except ValueError as er2:\n",
    "        print(f'ValueError: {file_path}: {er2}')\n",
    "        return None\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 1200\n",
    "create_features_dataframe(os.path.join(df_metadata_drugs['filepath'].iloc[ind],df_metadata_drugs['filename'].iloc[ind]),\n",
    "                          df_metadata_drugs['drug_std'].iloc[ind]) \n",
    "                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_list = Parallel(n_jobs=40, verbose = 5)(delayed(create_features_dataframe)(os.path.join(df_row['filepath'],df_row['filename']),df_row['drug_std']) \n",
    "                                                    for index, df_row in df_metadata_drugs.iterrows())\n",
    "df_features_combined = pd.concat(df_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_combined.to_pickle('/data/temp/athira/dlc_analysis/feats_combined_glutgaba_drugs_Jan31.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For DREADDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done  82 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=40)]: Done 208 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=40)]: Done 370 tasks      | elapsed:   41.8s\n",
      "[Parallel(n_jobs=40)]: Done 568 tasks      | elapsed:   59.3s\n",
      "[Parallel(n_jobs=40)]: Done 802 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=40)]: Done 1072 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=40)]: Done 1378 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=40)]: Done 1720 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=40)]: Done 1954 out of 1954 | elapsed:  3.4min finished\n"
     ]
    }
   ],
   "source": [
    "df_features_list_dreadds = Parallel(n_jobs=40, verbose = 5)(delayed(create_features_dataframe)(os.path.join(df_row['filepath'],df_row['filename']),df_row['drug_std']) \n",
    "                                                    for index, df_row in df_metadata_dreadds.iterrows())\n",
    "df_features_combined_dreadds = pd.concat(df_features_list_dreadds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_combined_dreadds.to_pickle('/data/temp/athira/dlc_analysis/feats_combined_glutgaba_dreadds_Feb06.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hampel filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.series.outlier_detection import HampelFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hampel_filter_skel(filepath):\n",
    "    \n",
    "    hampel_fn = f'/data/longterm/10/athira/HampelData/hampel_{os.path.basename(filepath)}'\n",
    "    if not os.path.exists(hampel_fn):\n",
    "        try:\n",
    "            df_skel = pd.read_hdf(filepath)\n",
    "\n",
    "        #     from sktime.transformations.series.outlier_detection import HampelFilter\n",
    "\n",
    "            transformer = HampelFilter(window_length=10)\n",
    "            df_skel_filt = df_skel.copy()\n",
    "\n",
    "            for i in list(df_skel.columns.get_level_values(1)):\n",
    "\n",
    "                test_x = df_skel.loc[:,('DLC_resnet50_Ciona_trackingMay25shuffle1_500000',i,'x')]\n",
    "                test_y = df_skel.loc[:,('DLC_resnet50_Ciona_trackingMay25shuffle1_500000',i,'y')]\n",
    "                df_skel_filt.loc[:,('DLC_resnet50_Ciona_trackingMay25shuffle1_500000',i,'x')] = transformer.fit_transform(test_x)\n",
    "                df_skel_filt.loc[:,('DLC_resnet50_Ciona_trackingMay25shuffle1_500000',i,'y')] = transformer.fit_transform(test_y)\n",
    "\n",
    "            df_skel_filt.to_pickle(f'/data/longterm/10/athira/HampelData/hampel_{os.path.basename(filepath)}')\n",
    "        except ValueError as er:\n",
    "            print(er, hampel_fn)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_metadata_drugs.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hampel_list = Parallel(n_jobs=30, verbose = 5)(delayed(hampel_filter_skel)(os.path.join(df_row['filepath'],df_row['filename'])) \n",
    "                                                    for index, df_row in df_metadata_drugs.iterrows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = os.path.join(df_metadata_drugs['filepath'][2801],df_metadata_drugs['filename'][2801])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_filt = hampel_filter_skel(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path2 = f'/data/longterm/10/athira/HampelData/hampel_{os.path.basename(test_path)}'\n",
    "test_path2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_filt.to_pickle(test_path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "for ind in random.sample(range(0, len(df_metadata_drugs.index)), 1):\n",
    "    file_fullpath = os.path.join(list(df_metadata_drugs.filepath)[ind],list(df_metadata_drugs.filename)[ind])\n",
    "    df_skeleton = pd.read_hdf(file_fullpath)\n",
    "    \n",
    "#     df_feat = create_features_dataframe(file_fullpath, list(df_metadata_drugs.drug)[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_skeleton[df_skeleton < 0] = np.nan\n",
    "df_skeleton = df_skeleton[(df_skeleton.iloc[:, df_skeleton.columns.get_level_values(2) == 'likelihood'] > 0.6).all(axis=1)]\n",
    "df_skeleton = df_skeleton.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_skeleton "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skel_array_x = df_skeleton.iloc[:,df_skeleton.columns.get_level_values(2)=='x'].values\n",
    "skel_array_y = df_skeleton.iloc[:,df_skeleton.columns.get_level_values(2)=='y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skel_array = df_skeleton.iloc[:,df_skeleton.columns.get_level_values(2)!='likelihood'].values.reshape(-1,49,2)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(skel_array_x[:,15],skel_array_y[:,15], cmap='jet', c=np.arange(0, len(skel_array_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sktime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.series.outlier_detection import HampelFilter\n",
    "from sktime.datasets import load_airline\n",
    "\n",
    "transformer = HampelFilter(window_length=10)\n",
    "skel_array_hat = np.zeros_like(skel_array)\n",
    "for i in range(skel_array.shape[1]):\n",
    "    test_x = pd.Series(skel_array_x[:,i])\n",
    "    test_y = pd.Series(skel_array_y[:,i])\n",
    "    skel_array_x_hat = transformer.fit_transform(test_x)\n",
    "    skel_array_y_hat = transformer.fit_transform(test_y)\n",
    "    skel_array_hat[:,i,0]=skel_array_x_hat\n",
    "    skel_array_hat[:,i,1]=skel_array_y_hat\n",
    "\n",
    "plt.scatter(skel_array_hat[:,15,0],skel_array_hat[:,15,1], cmap='jet', c=np.arange(0, len(skel_array_x_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curv_array =  get_curv_savgol(skel_array)\n",
    "curv_array_hat =  get_curv_savgol(skel_array_hat)\n",
    "fig, axes = plt.subplots(1,1, figsize = (15,4))\n",
    "\n",
    "axes.plot(curv_array[:,15])\n",
    "axes.plot(curv_array_hat[:,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curv_array_hat =  get_curv_savgol(skel_array_hat)\n",
    "plt.scatter(curv_array_hat[:,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
